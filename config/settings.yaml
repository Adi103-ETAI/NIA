# NIA Configuration for Phase 1.1

# Voice Interface Settings
voice:
  hotkey: "space"
  tts_engine: "pyttsx3"
  tts_rate: 165
  # Set to a specific voice ID from your system, or null to use the default
  tts_voice_id: null
  # Phrase chunking settings for streaming TTS
  chunk_chars_min: 60
  chunk_chars_max: 240
  # Regex to identify sentence boundaries for cleaner chunking
  sentence_boundary_regex: "[.!?…]+\\s"

# Hybrid listening configuration
hybrid:
  passive_enabled: false       # Enable passive wake-word listening
  wake_words:
    - "nia"
    - "hey nia"
    - "okay nia"
    - "buddy"
    - "hey buddy"

# Speech-to-Text and Voice Activity Detection
stt:
  engine: "vosk"           # 'google' (online) or 'vosk' (offline, requires model)
  vosk_model_path: "model/vosk-model-small-en-us-0.15"
  # Voice Activity Detection (VAD) settings for barge-in
  vad: false
  vad_engine: "silero"     # 'silero' or 'none'
  vad_aggressiveness: 2    # Reserved for engines that use aggressiveness
  vad_trigger_ms: 250      # Milliseconds of speech to start listening (hysteresis)
  vad_release_ms: 300      # Milliseconds of silence to stop listening (end-of-speech)
  deepfilternet: true
  deepfilternet_model_dir: "deepfilternet2"  # Path to DFN model directory

# STT Enhancement Settings
stt_enhancement:
  model_dir: "models/DeepFilterNet"  # DeepFilterNet model directory
  enable: true                       # Enable audio enhancement

# Brain (LLM) settings
brain:
  model: "qwen3:4b"        # Default Ollama model to use
  fallback_models:
    - "phi4-mini:3.8b"
    - "zephyr:7b"
  system_prompt: "You are NIA, a helpful and friendly voice assistant. Keep your responses concise and conversational. Speak naturally as if you're having a real conversation. Be warm, engaging, and helpful."
  transport: "http"        # 'http' (streaming) or 'cli' (not implemented)
  stream: true
  timeout_s: 180           # Increased timeout for slower systems
  cancel_on_barge_in: true

# Autonomy agent configuration
autonomy:
  enabled: true
  suggestion_interval_s: 90
  confidence_threshold: 0.6  # Only suggest if confidence >= this value
  decision_keywords:
    - "should i"
    - "what if"
    - "maybe"
    - "i think"
    - "i'm not sure"
    - "help me decide"
    - "i need to"
    - "i want to"
    - "i have to"
    - "i should"
    - "i could"
    - "i might"
    - "what do you think"
    - "any suggestions"
    - "any ideas"
    - "what would you do"
  high_value_topics:
    - "work"
    - "project"
    - "meeting"
    - "deadline"
    - "plan"
    - "schedule"
    - "task"
    - "problem"
    - "issue"
    - "decision"
    - "choice"
    - "option"
    - "strategy"
  hesitation_patterns:
    - "\\b(um|uh|er|ah|hmm|well|so|like|you know)\\b"
    - "\\b(i mean|i guess|i suppose|sort of|kind of)\\b"
  repetition_threshold: 2  # Suggest if same topic mentioned this many times
  # Legacy prompts (fallback)
  prompts:
    - "Would you like a summary of recent updates?"
    - "Need me to set a reminder for anything?"
    - "I can check your schedule if you want."
  # Confirmation settings
  confirm_before_speaking: true
  confirm_prompt: "I have a suggestion that might help—would you like to hear it?"
  confirm_yes_keywords:
    - "yes"
    - "sure"
    - "okay"
    - "go ahead"
    - "please"
    - "sounds good"
  confirm_no_keywords:
    - "no"
    - "not now"
    - "later"
    - "skip"
    - "dismiss"
  confirm_timeout_s: 4
  # Semantic memory integration for autonomy suggestions
  use_memory: true
  max_memory_snippets: 5

# Semantic Memory Settings
memory:
  enabled: true
  db_path: "data/memory"
  collection: "conversations"
  embedding_model: "nomic-embed-text"
  enable_embeddings: true
  max_recent_queries: 5
  min_similarity_score: 0.7

# Long-term Knowledge Settings
knowledge:
  enabled: true   # Re-enabled now that nomic-embed-text model is available
  retriever_type: "vector"
  top_k: 5
  sources: []
  index_path: "data/knowledge"